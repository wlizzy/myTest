9种常见的反爬虫策略思路
17 人赞同了该文章
在上篇文章反爬虫到底是怎么一回事？中，企通查为大家介绍了反爬虫技术出现的契机和基本分类，本文将为大家介绍9种常见的反爬虫策略思路。
反爬虫，是指对扫描器中的网络爬虫环节进行反制，通过一些反制策略来阻碍或干扰爬虫的正常爬行，从而间接地起到防御目的。
爬虫的反制策略有很多，总体可归为基于IP的反爬虫和基于爬行的反爬虫两大类。
对于基于IP的反爬虫，主要思路就是通过人为或部分策略来识别出爬虫的IP并进行屏蔽、阻止、封禁等操作。
对基于爬行的反爬虫，其思路主要是在爬虫的爬行中设置爬行障碍，让其陷入死循环；或者用一些无意义的URL来填充其爬行队列，从而阻止其对正常URL进行后续的漏洞审计。
9种常见的反爬虫策略思路
01 封IP
网站运维人员在对日志进行分析时有时会发现同一时间段内某一个或某几个IP访问量特别大，由于爬虫是通过程序来自动化爬取页面信息的，因此其单位时间的请求量较大，且相邻请求时间间隔较为固定，这时就基本可以判断此类行为系爬虫所为，此时即可在服务器上对异常IP进行封锁。
02 封User-Agent
User-Agent是请求头域之一，服务器从User-Agent对应的值中是被客户端的使用信息。
User-Agent的角色就是客户端的身份标识。很多的爬虫请求头就是默认的一些很明显的爬虫头python-requests/2.18.4，诸如此类，当发现携带有这类headers的数据包，直接拒绝访问，返回403错误。
除了User-Agent之外，可利用的头域还有Host和Referer。这种验证请求头信息中特定头域的方式既可以有效地屏蔽长期无人维护的爬虫程序，也可以将一些爬虫初学者发出的网络请求拒之门外。
03 封Cookie
Cookie反爬虫指的是服务器通过校验请求头中的Cookie值来区分正常用户和爬虫程序的手段，服务器对每一个访问网页的人都会给其一个Cookie，有的扫描爬虫单纯为了爬取链接，并不会对Cookie进行处理和响应。
当某个Cookie访问超过某一个阀值时，就对其进行封禁，过一段时间再放出来。
也可以把Cookie和JavaScript结合起来实现反爬虫从而提高爬虫难度，这种手段被广泛应用在Web应用中。
04 javascript渲染
由 JavaScript 改变 HTML DOM 导致页面内容发生变化的现象称为动态渲染。
由于编程语言没有像浏览器一样内置JavaScript解释器和渲染引擎，所以动态渲染是天然的反爬虫手段。
网页开发者将重要信息放在网页中但不写入html标签中，而浏览器会自动渲染<script>标签中的js代码将信息展现在浏览器当中，而爬虫是不具备执行js代码的能力，所以无法将js事件产生的信息读取出来。
05 验证码验证
当某一用户访问次数过多后，就自动让请求跳转到一个验证码页面，只有在输入正确的验证码之后才能继续访问网站。
06 ajax异步传输
访问网页的时候服务器将网页框架返回给客户端，在与客户端交互的过程中通过异步ajax技术传输数据包到客户端，呈现在网页上，爬虫直接抓取的话信息为空。
07 图片伪装
图片伪装指的是将带有文字的图片与正常文字混合在一起，以达到“鱼目混珠”的效果。
这种混淆方式并不会影响用户阅读，但是可以让爬虫程序无法获得“所见”的文字内容。
08 CSS偏移
这种方法是利用 CSS 样式将乱序的文字排版为人类正常阅读顺序的行为。
如果不细心观察，爬虫工程师很容易被爬取结果糊弄。这种混淆方法和图片伪装一样，并不会影响用户阅读。
例如：
HTML 文本中的文字：我的学号是 1308205，我在北京大学读书。
浏览器显示的文字：我的学号是 1380205，我在北京大学读书。
爬虫提取到的学号是 1308205，但用户在浏览器中看到的却是 1380205。
09 SVG映射
SVG 是用于描述二维矢量图形的一种图形格式。它基于 XML 描述图形，对图形进行放大或缩小操作都不会影响图形质量。
由于 SVG 中的图形代表的也是一个个文字，所以在使用时必须在后端或前端将真实的文字与对应的 SVG 图形进行映射和替换。
通过用矢量图形代替具体文字，不会影响用户正常阅读，但爬虫程序却无法像读取文字那样获得 SVG 图形中的内容。
除此之外还有Referer字段反爬、延时操作、网页iframe框架嵌套、csrf防护、限制每日下载量、DDOS防护、字体反爬虫等方式，感兴趣的小伙伴们可以自行查阅相关资料了解。
虽然爬虫措施有很多，但爬虫高手依旧可以绕过反爬虫机制，每一种方法都不是绝对安全的。因此对于有版权的内容和隐私数据，决不能为了“展现技术”而去肆意爬取。